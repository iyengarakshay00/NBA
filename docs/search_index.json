[["index.html", "NBA Project Chapter 1 Introduction", " NBA Project Yunchen Jiang, Akshay Iyengar, Conor Ryan 2022-12-13 Chapter 1 Introduction We chose to explore various components of NBA data because we all have a common interest in the NBA. For any readers unfamiliar, the NBA is the National Basketball Association and is the highest level of professional basketball played in North America. As a sport, basketball provides a rich opportunity for data collection, which is why we were interested in seeing if we could create interesting visualizations from it. All parts of the sport – from the many different teams and players, to the many different head-to-head games throughout the season, to the granular play-by-play shooting activity – provide potentially interesting areas for us to explore within data. One important phenomenon to note was the “bubble” period created by COVID-19 during the 2020 season. This was the NBA’s solution to enable the continuation of the season despite the pandemic; it involved a bio-secured facility in Florida where players were silo’d from the world while they played games to finish the season. In much of our analysis, we focused on this period to try and see if there were any interesting trends that came about during the bubble period, relative to the surrounding time periods. "],["proposal.html", "Chapter 2 Proposal 2.1 Research topic 2.2 Data availability", " Chapter 2 Proposal 2.1 Research topic Our research topic generally deals with NBA player/game data. Since that is such a big area, we will focus our attention in particular to more recent years. If needed, we may also later focus on particular teams to make the task manageable and allow us to gain more interesting insights. The primary topic we intend to explore is if there have been any significant shifts in basketball patterns due to COVID. This will involve considering three periods: pre, during (the “bubble” phenomenon), and post. We’d like to understand if any players’ stats in particular shifted dramatically across these periods. It would also be interesting to understand if the significant “shifts” across all players were typical over such a period, or if the “bubble” might have exacerbated these trends. Another topic we’d like to explore is if any fundamentals of gameplay changed across these periods. For example, did people start shooting more three-pointers or half-court-shots? Did free-throw accuracy change noticeably? One complication in all of this will be trying to isolate normal trends from those created by COVID. For example, if we observe any variation, is that variation within a reasonable expectation historically in the NBA, or does it seem like a true outlier potentially attributable to the COVID period? 2.2 Data availability There are a lot of places to get basketball stats from, so we will consider several sources and ultimately focus on the one that works best in practice for the questions we’re trying to answer. Various sports news sites, like ESPN, CBS, etc. will be a good starting point. The data from such sources is typically collected by the organizations themselves. We can trust these with relative ease, as these are good sources who put their reputation on the line by reporting with these statistics. Data is updated in near real time, so we will look to collect their historical data and “lock” it in time. These sites typically do not make their data available in any particularly friendly way, so we will need to web scrape these pages, download them in HTML format, and extract tabular format from them with R. We will also need to be careful when getting the data and not violate their privacy policies. There are no known issues with this data currently. There are also many other external organizations that aggregate data which we can try and use. Basketball-reference.com (run by Sports-reference.com) will be one such valuable resource to us. Their data is extremely verbose, potentially moreso than that provided by news organizations, so it may end up being more useful. One thing worth considering is that they serve as an aggregator of data, meaning they combine proprietary data from many other sources, so although they do not do collection themselves, they may also be the only way of retrieving the data in this format. They do not name their upstream vendors. We will look to do more research and try and get as close to the data collectors as possible, but it’s feasible they are the best option simply because of licensing agreements and the obviously strict nature of professional sports statistics. Their Terms of Use makes clear that they allow anyone to download and use their data as long as a reference is provided and the data is not used to compete against them as a provider. They restrict web-scraping to twenty requests per minute, so we will remain mindful of this. Most of their statistics pages also make it relatively easy to just download a CSV, so to “lock” our data in place and avoid any scraping issues, we will seek to manually download their data where feasible. This will then be simple enough to import into R. There are no known issues with their data. They claim to respond to all email, so if we have issues, we can try and contact them (although they request a week to respond). Bibliography: Wikipedia StatMuse ESPN Basketball-Reference "],["data.html", "Chapter 3 Data 3.1 Sources 3.2 Cleaning / transformation 3.3 Missing value analysis", " Chapter 3 Data 3.1 Sources 3.1.1 Season data Our first data source was ESPN, which we used for aggregate team performance across several years. ESPN offers no convenient way to download data, so we resorted to scraping. We needed to make sure that webscraping the data from the site was legal and ethical. That is why we didn’t edit any of the numbers and made sure the data was in the correct format. After using a library called Rvest, we were able to grab both western and eastern conferences as a table. Then, we repeated this for multiple seasons in order to get data for all teams and growth across the years. Some of the problems with the table was that it wasn’t in order like the ESPN by position. The table wasn’t combined and there wasn’t indicators for years or conferences. The teams also were in a format that wouldn’t be able to be grouped in a graph. For example, the team was like “Milwakee Bucksz” which is different than the team name because it had the letter or position combined. This took some cleaning and transformation, which we discuss below. There were about 90 records considering 3 seasons and 30 NBA teams. Some of the variables are team name, team name adjusted (which is a clean abbreviated name for team), conference type (western or eastern), year (when season started), and more. Some of the numerical variables dealt with points per game, opponent points per game, wins, and losses. 3.1.2 Shot data We also pulled granular shot data directly from the NBA’s public APIs for games from 2017 to 2022. The NBA itself collects and publishes this data. They make it available for use (according to their Terms of Use) so long as it is not used for profit, and as long as NBA.com is given attribution. Consider this that attribution, so usage of this data is permissible for this project. The NBA offers a substantial number of APIs for accessing different statistics. We used a python package to help access those APIs. Specifically, we downloaded two datasets using this API: - shot-by-shot locations (as in, place on the basketball court). Each row reflects one shot, along with identifying columns like who shot it, their team at the time, how far it was from the hoop, date, and season. This is a substantial dataset with nearly 500k rows and over 50mb in size. - aggregated total number of shots by player and season. This is a small dataset since it’s aggregated; no more than 3k rows. 3.2 Cleaning / transformation 3.2.1 Season data Scraping and cleaning is shown for this dataset in data/pull/Season.R. Getting this data into a tabular csv form was a lengthy process. Extracting using rvest gets the table into separated table values. There were 4 tables for one year using rvest. Each table represented one of two things either a list of teams or the list of variable values related to the team for the season performance per conference. We had to join the the teams with the list of values using its row names. Later on, row names was converted into an integer so we could have a position of the team within the respective conference. We also added a category column to indicate whether eastern or western conference something that might be useful to denote. Once that was done, the eastern and western conference tables were merged into one using a union command. We added a year, which would be converted to an integer to denote the start of the season for that table. This was repeated for the next two following seasons. In order to get a big table full of all 3 seasons we union_all the data frames to get all value combinations for the final data frame for season performances. A unique thing while looking at the data set was the name for the team was combined with positions/bye performances, which were denoted by special letters such as y or z. In order to clean this, we created a column called ACT_TEAM, which is an abbreviation of the letters of the team. Using a regular expression formula, we were able to extract the 3 NBA letter. Now, not everything can be accurate to the NBA abbreviation, which is why human oversight over data is so important. We were able to adapt and change 4 of the abbreviations to match the NBA ones. 3.2.2 Shot data Extracting the shot data took a substantial amount of time and effort, so we wanted to explicitly note that time commitment here. There were several reasons for this: - The Python library, while helpful relative to the NBA’s janky API, was poorly documented. - We discovered that the NBA’s API has some secret rate-blocking mechanism to prevent DDOS. We figured this out after getting our IP address temporarily blocked by their servers. After resolving this, we learned that this meant in practice we had to sleep one second between API calls. This doesn’t sound like much of a problem, but the API to extract granular player shots requires one call per player and season. There are several hundreds of players each season, and each API call also might take several seconds itself, so it would have taken many hours to get the entirety of shot data. To resolve this, we ended up only pulling the shots of the 100 players who shot the most each season. This top-shooting-player information was determined by the data in data/files/fga_by_player_2017-22.csv (pulled via data/pull/fga_by_player.py). Then we extracted shot data via data/pull/shot_data.py and stored it in data/files/shot_data_2017-22.csv. This is still a substantial amount of data, and we provide justification for this approach later in Results – long story short, this allows us to analyze roughly 50% of shot data without wasting hours pulling the data. On the other hand, this data did not require much cleaning / transformation, since we did most manipulation at pull-time as shown in the Python scripts; it only involved things like selecting and renaming columns. In R before visualizing, we also did a few simple things to coerce column types and appropriately label the different play periods (pre, during, and post-bubble) so we could visualize those periods easily. 3.3 Missing value analysis 3.3.1 Season data Below shows missing values for one of the seasonal data tables. It has no missing data as you can see; there is a complete case file for all the rows. This is because when getting the ESPN data, it contains all of the statistics for the seasons for every team. This is definitely one of the perks of getting data directly from the source itself. 3.3.2 Shot data Like above, our shot dataset also contained no missing data: "],["results.html", "Chapter 4 Results 4.1 Seasonal Data Bubble Year and Beyond 4.2 Shot data", " Chapter 4 Results 4.1 Seasonal Data Bubble Year and Beyond Here we grab the data, which is referred to in the data section. We end up grabbing from espn and merging the tables together based on the teams, conferences, and years. This is talked about more in the data section. We start with the first graph below based on the NBA data, where we see the fluctuations in points in a Cleveland dot chart where we see by year if the dots change per team per year. We did this where we organized from top down by year 2019 PPG descending order. Here we can see diverging points where some of the teams have less PPG than years before. For example, Milwaukee increased from the bubble year which is 2019 whereas Denver decreased in PPG. Charlotte increases steadily each year in offensive points per game. Also, other patterns explored can show how PPG in 2019 related to playoff runs or playoff positions.This chart will help determine if offensive identity was different from the bubble than years past. In the next graph, we want to plot opponents points per game versus points per game scored. We are going to take a specific look at 2019 so we can plot offensive and defensive prowess and see what teams in which conferences benefited that year. Specifically, we separate by conference and see in-depth analysis with teams. During the bubble, we can see from the graph that some teams like Milwaukee and Boston had both offensive and defensive prowess from the gap in the bars of opponent ppg and ppg. Some teams like Phoenix had both offesnive and defensive ability almost equal. For the next graph, we can see that there are three teams that performed well from each conference in 2019. We get to take a deeper look at it and see if their position changed over the years. This can help show the audience that position of teams change over the years. From this graph, we can see LAL somehow continuously goes down considering they are the number one team from the bubble. Toronto especially takes a massive plummet in its ranking over the next year. Boston overall goes up in its ranking and we see that today especially how it performs in the NBA. We get to see some the trending three teams from the bubble again from each conference. The number of wins is shown for those same teams. We can now see another statistic from them over the years. A cool feature is that you can label them with numbers which is what we precisely do with the lines to see the patterns. We can see the graph from below matches some of the position pattern from above. This makes sense because position and record wins/losses are related to each other. We can see that Toronto might have just had an outlier year based on the number of losses. We could potentially attribute the year before to luck or this one to an injuries. 4.2 Shot data As noted in the data sources section, for this data, we only pulled shot data for the top 100 players each season. The graph below shows that doing so, regardless of season, generally accounts for about 50% of the season’s shots. First, this justifies our decision to only pull the first 100 players’ shots. This gave us a substantial amount of data without needing to spend time retrieving the long tail of players. Of course, this means the following analysis and plots all come with the caveat that they’re really only applicable for the 50% of shots from the “shootingest” players. Second, the plot below indicates that by season, the distribution of shots taken by player rank has been roughly consistent. Even during the 2019-20 season (which included the bubble), this remained the case. In this regard, it seems as though the bubble had no impact. Note that we cannot break this data into only the bubble period, because this data is not available broken down by date (unless we downloaded every player’s shot data – which we wanted to avoid as discussed earlier). The graphs below show heatmaps of the count of shots taken from each position on the court, broken down by pre/during/post-bubble periods. There are a few things worth noting here: Figuring out how to properly draw the courts was tedious and took a lot of time. This was achieved with the assistance of this article, which showed how to do something similar in Python. Our initial attempt at plotting these heatmaps wasn’t particularly useful because the number of shots taken near the hoop far exceeds any other court region, which meant the only area that had any color was under the hoop. So, we rescaled by taking the log of shot count, in order to get a better visual color gradation. Keep in mind that the colors here are therefore not proportional to true shot count. In terms of analysis on these graphs, it’s hard to conclude anything strongly. The reality of shots during the bubble period is that there were far fewer, to the point where some places on the court had no shots at all. This makes the heatmaps look quite different and so they are difficult to compare. Perhaps the only thing we might conclude is in regards to shots taken on the three point line. In the non-bubble periods, there are three darker “clusters” in the middle, on the top left, and on the top right of the three point line. However, for the bubble plot, it seems as though there’s no obvious clustering of shots such that they’re evenly distributed along the three point line. The graphs below help dig further into the clustering noted above. They plot each shot taken as a point, along with countour curves that surround the most prominent clusterings of points. This approach helps us see shot locations more granularly. The countours here are more or less the same across plots, except for in the regions above the three point line as described above. These contours validate our earlier conclusion: in the bubble, shots were taken relatively evenly along the three point line, while in the other periods there was some sort of triad of clustering. The graph below investigates shot accuracy instead of total shots taken. Here, the rows reflect a 10-unit square of the court; for example, -10_300 is the region on the court spanning -20 to -10 on the x-axis and 300 to 310 on the y-axis. For reference, the bottom left corner of each court as drawn above is at (-220, 0) and the top right corner is at (220, 350). This matches the convention of the location data exactly as given by the NBA. We only show the 40 regions that had the highest number of total shots taken. Although not universally true, this plot shows that accuracy in the bubble, by court region, generally was higher than in the other periods. Accuracy in the bubble was highest for a disproportionate number of regions (nearly half), and was lowest for roughly 1/3 of regions (which is expected). This outpaces both other periods. As such, we can conclude from this graph that accuracy in the top court regions was higher in the bubble. "],["interactive-component.html", "Chapter 5 Interactive component", " Chapter 5 Interactive component "],["conclusion.html", "Chapter 6 Conclusion 6.1 Lessons learned 6.2 Future work", " Chapter 6 Conclusion The main takeaways of our exploration start with the process of beginning a data science visualization project. We were able to see different breakdown of player data and season performance. The graphs visually entice the audience and provide a powerful understanding about how teams performed in different years in a professional basketball league. This approach to portraying NBA data makes observing the patterns we noticed more accessible to a wider audience. Overall, we had a lot of success in uncovering interesting trends through our visualizations. Throughout our exploration, we tended to focus on the “bubble” to understand if gameplay changed during this unusual period of NBA history. In many cases, we noticed interesting trends during the bubble relative to the surrounding years. It would be interesting to better understand the causes behind these patterns. It’s worth noting that this was not universally true; in some cases we noticed no discernible change during the bubble. 6.1 Lessons learned One lesson learned was that gathering the right data takes the right questions and right primary sources. The right kinds of color and visualizations do really make visualizations more accessible and successful. Audiences can be pulled in to a really good story and the visualization can tell that story if it fits or makes sense with the data. We also learned that extracting data is not always easy. Indeed, in our case it took a significant amount of time for some of our team members. In general, as we go forward as data scientists, this is an important lesson to keep in mind: real world data is messy and getting good data might be the hardest part of some projects. 6.2 Future work For our seasonal data, we would love to pull a complete history of all seasons’ data. This would be a lengthy amount considering the NBA extends back to 100s of years ago. Also, the team data would look very different as there were different teams and league points can’t be compared because of the size of the league back then and now. It would be interesting to explore additional variables such as coach impact and injuries. These variables might be able to provide a powerful association for how a team performs in the league and in post-season/playoffs. In regards to shot data, in the future we’d like to pull data for all players instead of only the top 100. With enough time and resources, this should be possible. Doing so would roughly double our dataset, so hopefully the trends we’ve observed here would hold. This is the main limitation of the analysis we did on shot data. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
